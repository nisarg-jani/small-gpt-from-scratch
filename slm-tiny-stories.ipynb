{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRSkH2EeYEjk"
   },
   "source": [
    "## Step-1 Importing Tiny Story Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:02:47.225425Z",
     "iopub.status.busy": "2025-11-09T07:02:47.224623Z",
     "iopub.status.idle": "2025-11-09T07:02:53.407000Z",
     "shell.execute_reply": "2025-11-09T07:02:53.406219Z",
     "shell.execute_reply.started": "2025-11-09T07:02:47.225389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied train.bin → /kaggle/working\n",
      "Copied validation.bin → /kaggle/working\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "input_dir = \"/kaggle/input/slm-preprocessed-bin\"\n",
    "working_dir = \"/kaggle/working\"\n",
    "\n",
    "for fname in [\"train.bin\", \"validation.bin\"]:\n",
    "    src = os.path.join(input_dir, fname)\n",
    "    dst = os.path.join(working_dir, fname)\n",
    "    if not os.path.exists(dst):  # avoid duplicate copy\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\"Copied {fname} → {working_dir}\")\n",
    "    else:\n",
    "        print(f\"{fname} already exists in {working_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-09T07:02:53.415921Z",
     "iopub.status.busy": "2025-11-09T07:02:53.415691Z",
     "iopub.status.idle": "2025-11-09T07:03:01.743978Z",
     "shell.execute_reply": "2025-11-09T07:03:01.743281Z",
     "shell.execute_reply.started": "2025-11-09T07:02:53.415901Z"
    },
    "id": "SNjNI9h1YJ7f",
    "outputId": "6f9c5411-74d9-4cc0-e5a5-c5047b30b0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyarrow-22.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:01.745200Z",
     "iopub.status.busy": "2025-11-09T07:03:01.744909Z",
     "iopub.status.idle": "2025-11-09T07:03:05.191601Z",
     "shell.execute_reply": "2025-11-09T07:03:05.190521Z",
     "shell.execute_reply.started": "2025-11-09T07:03:01.745149Z"
    },
    "id": "HABpx7y4YOdY",
    "outputId": "d79ed6bb-6a32-4e6b-8bc9-04c81bc78fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:05.195053Z",
     "iopub.status.busy": "2025-11-09T07:03:05.194361Z",
     "iopub.status.idle": "2025-11-09T07:03:10.259932Z",
     "shell.execute_reply": "2025-11-09T07:03:10.259240Z",
     "shell.execute_reply.started": "2025-11-09T07:03:05.195011Z"
    },
    "id": "dgV1uK-FYY7V"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:10.261190Z",
     "iopub.status.busy": "2025-11-09T07:03:10.260783Z",
     "iopub.status.idle": "2025-11-09T07:03:23.374868Z",
     "shell.execute_reply": "2025-11-09T07:03:23.374074Z",
     "shell.execute_reply.started": "2025-11-09T07:03:10.261147Z"
    },
    "id": "yuRhPbYKYp5F"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c716be9e7694495b5cd818afec2aac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e2903087394f468959ba213278488d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00004-2d5a1467fff108(…):   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f8e83c805e48b68a696a0fdc11c5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00004-5852b56a2bd28f(…):   0%|          | 0.00/248M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ca8ee5cb2f4218bbe4345e51dec760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00002-of-00004-a26307300439e9(…):   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c26c1d944f449abb51e267b8eba109c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00003-of-00004-d243063613e5a0(…):   0%|          | 0.00/248M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac6f513ec274f92b967d284f8aa0111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001-869c898b5(…):   0%|          | 0.00/9.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadb28e385dd48afbe8e79759f946550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30806614c99e4331b9234edfcf5e1135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"roneneldan/TinyStories\") #https://huggingface.co/datasets/roneneldan/TinyStories/viewer/default/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:23.376216Z",
     "iopub.status.busy": "2025-11-09T07:03:23.375696Z",
     "iopub.status.idle": "2025-11-09T07:03:23.381097Z",
     "shell.execute_reply": "2025-11-09T07:03:23.380409Z",
     "shell.execute_reply.started": "2025-11-09T07:03:23.376190Z"
    },
    "id": "Atde2KLDY8Al",
    "outputId": "5702da55-6287-44b8-de5a-dca07241133b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2119719\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 21990\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBqT7EC7-2xP"
   },
   "source": [
    "## Step-2: Tokenization of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:23.382232Z",
     "iopub.status.busy": "2025-11-09T07:03:23.381965Z",
     "iopub.status.idle": "2025-11-09T07:03:26.832133Z",
     "shell.execute_reply": "2025-11-09T07:03:26.831102Z",
     "shell.execute_reply.started": "2025-11-09T07:03:23.382210Z"
    },
    "id": "-c_eeimC9MXf",
    "outputId": "680b7be1-4c25-44e5-840d-0fbf47aa9e46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:26.833735Z",
     "iopub.status.busy": "2025-11-09T07:03:26.833411Z",
     "iopub.status.idle": "2025-11-09T07:03:26.879938Z",
     "shell.execute_reply": "2025-11-09T07:03:26.879075Z",
     "shell.execute_reply.started": "2025-11-09T07:03:26.833699Z"
    },
    "id": "NmQCBmeH_jg1"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:26.881067Z",
     "iopub.status.busy": "2025-11-09T07:03:26.880785Z",
     "iopub.status.idle": "2025-11-09T07:03:31.230170Z",
     "shell.execute_reply": "2025-11-09T07:03:31.228450Z",
     "shell.execute_reply.started": "2025-11-09T07:03:26.881042Z"
    },
    "id": "A9peQcUg_wBQ"
   },
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:31.231881Z",
     "iopub.status.busy": "2025-11-09T07:03:31.231561Z",
     "iopub.status.idle": "2025-11-09T07:03:31.239241Z",
     "shell.execute_reply": "2025-11-09T07:03:31.238444Z",
     "shell.execute_reply.started": "2025-11-09T07:03:31.231854Z"
    },
    "id": "2yS7y2Ca6B4A"
   },
   "outputs": [],
   "source": [
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:31.240218Z",
     "iopub.status.busy": "2025-11-09T07:03:31.239916Z",
     "iopub.status.idle": "2025-11-09T07:03:32.392632Z",
     "shell.execute_reply": "2025-11-09T07:03:32.391794Z",
     "shell.execute_reply.started": "2025-11-09T07:03:31.240191Z"
    },
    "id": "mKL55mMp_0mo"
   },
   "outputs": [],
   "source": [
    "def process(example):\n",
    "    ids = enc.encode_ordinary(example['text'])  # Tokenize the text\n",
    "    # Ensure sequence length does not exceed block_size\n",
    "    ids = ids[:block_size]  # Trim if longer than block_size\n",
    "    out = {'ids': ids, 'len': len(ids)}  # Save 'ids' and 'len' for later access\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:32.394002Z",
     "iopub.status.busy": "2025-11-09T07:03:32.393707Z",
     "iopub.status.idle": "2025-11-09T07:03:33.173449Z",
     "shell.execute_reply": "2025-11-09T07:03:33.172610Z",
     "shell.execute_reply.started": "2025-11-09T07:03:32.393976Z"
    },
    "id": "S02DTRre7C-O",
    "outputId": "969aadfe-7044-4676-b27b-4e93e1dbdca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train.bin and val.bin already exist in /kaggle/working — skipping tokenization.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"/kaggle/working\"\n",
    "\n",
    "train_bin_path = os.path.join(data_dir, \"train.bin\")\n",
    "val_bin_path = os.path.join(data_dir, \"validation.bin\")\n",
    "\n",
    "# Checking if both preprocessed .bin files already exist, if yes then no need to do tokenization again\n",
    "if os.path.exists(train_bin_path) and os.path.exists(val_bin_path):\n",
    "    print(\"✅ train.bin and val.bin already exist in /kaggle/working — skipping tokenization.\")\n",
    "else:\n",
    "    print(\"⚙️ train.bin or val.bin not found — running tokenization...\")\n",
    "\n",
    "    # run your tokenization pipeline\n",
    "    tokenized = ds.map(\n",
    "        process,\n",
    "        remove_columns=['text'],\n",
    "        desc=\"Tokenizing the splits\",\n",
    "        num_proc=os.cpu_count(),\n",
    "    )\n",
    "\n",
    "    print(tokenized['train'][0])\n",
    "\n",
    "    # save tokenized dataset to .bin\n",
    "    for split in tokenized.keys():\n",
    "        dset = tokenized[split]\n",
    "        arr_len = np.sum(dset['len'], dtype=np.uint64)\n",
    "        filename = os.path.join(data_dir, f\"{split}.bin\")\n",
    "        arr = np.memmap(filename, dtype=np.uint16, mode='w+', shape=(arr_len,))\n",
    "        idx = 0\n",
    "        for i in tqdm(range(len(dset)), desc=f'Writing {split}.bin'):\n",
    "            arr[idx: idx + dset[i]['len']] = dset[i]['ids']\n",
    "            idx += dset[i]['len']\n",
    "        arr.flush()\n",
    "\n",
    "    print(\"✅ Tokenization completed and saved train.bin / val.bin to /kaggle/working.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sHQa6EK_419"
   },
   "source": [
    "## Step 3: Create Input-Output batches for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:34.419860Z",
     "iopub.status.busy": "2025-11-09T07:03:34.419660Z",
     "iopub.status.idle": "2025-11-09T07:03:35.701772Z",
     "shell.execute_reply": "2025-11-09T07:03:35.700802Z",
     "shell.execute_reply.started": "2025-11-09T07:03:34.419845Z"
    },
    "id": "XaEcXzh6AzqA"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:35.702909Z",
     "iopub.status.busy": "2025-11-09T07:03:35.702631Z",
     "iopub.status.idle": "2025-11-09T07:03:36.629538Z",
     "shell.execute_reply": "2025-11-09T07:03:36.628606Z",
     "shell.execute_reply.started": "2025-11-09T07:03:35.702883Z"
    },
    "id": "jipuvz1cvt6i"
   },
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # Recreate np.memmap every batch to avoid memory leaks\n",
    "    if split == 'train':\n",
    "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
    "    else:\n",
    "        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n",
    "\n",
    "    # Ensure indices are chosen such that sequences are within the block_size\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))  # Make sure we have enough tokens for the block\n",
    "\n",
    "    # Slice each sequence to ensure it's exactly block_size long\n",
    "    x = torch.stack([torch.from_numpy(data[i:i+block_size].astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy(data[i+1:i+1+block_size].astype(np.int64)) for i in ix])\n",
    "\n",
    "    # Move data to GPU if using CUDA\n",
    "    if device_type == 'cuda':\n",
    "        # Pin arrays for asynchronous transfer to GPU\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYmcWXtNP73G"
   },
   "source": [
    "## Step 4: Define the SLM Model Architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:28:31.834885Z",
     "iopub.status.busy": "2025-11-09T09:28:31.834320Z",
     "iopub.status.idle": "2025-11-09T09:28:31.857131Z",
     "shell.execute_reply": "2025-11-09T09:28:31.856506Z",
     "shell.execute_reply.started": "2025-11-09T09:28:31.834862Z"
    },
    "id": "GFGBOJ4xP9w3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from contextlib import nullcontext\n",
    "import os\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "    def forward(self, x):\n",
    "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.flash = hasattr(F, 'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                       .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "\n",
    "        if self.flash:\n",
    "            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n",
    "        else:\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v\n",
    "\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int\n",
    "    vocab_size: int\n",
    "    n_layer: int\n",
    "    n_head: int\n",
    "    n_embd: int\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte=nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe=nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop=nn.Dropout(config.dropout),\n",
    "            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f=LayerNorm(config.n_embd, config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.transformer.wte.weight = self.lm_head.weight  # weight tying\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
    "    \n",
    "        tok_emb = self.transformer.wte(idx)             # (b, t, n_embd)\n",
    "        pos_emb = self.transformer.wpe(pos)             # (t, n_embd) -> broadcasts to (b,t,n_embd)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x)                        # (b, t, vocab_size)\n",
    "        return logits\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate tokens given a conditioning sequence.\n",
    "        idx: Tensor of shape (B, T)\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop context if it exceeds block size\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            \n",
    "            # forward pass → logits\n",
    "            logits = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            \n",
    "            # top-k filtering (nucleus sampling)\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            \n",
    "            # sample from distribution\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            # append sampled token\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        \n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:28:33.005993Z",
     "iopub.status.busy": "2025-11-09T09:28:33.005713Z",
     "iopub.status.idle": "2025-11-09T09:28:33.019901Z",
     "shell.execute_reply": "2025-11-09T09:28:33.019184Z",
     "shell.execute_reply.started": "2025-11-09T09:28:33.005972Z"
    },
    "id": "qzNiBMsMfGt3"
   },
   "outputs": [],
   "source": [
    "config = GPTConfig(\n",
    "    vocab_size=50257,\n",
    "    block_size=128,\n",
    "    n_layer=6,\n",
    "    n_head=6,\n",
    "    n_embd=384,\n",
    "    dropout=0.15, #0.1\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "model = GPT(config)\n",
    "\n",
    "block_size = config.block_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_a8Rd-0S_WC"
   },
   "source": [
    "## Step 5: Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:37.687882Z",
     "iopub.status.busy": "2025-11-09T07:03:37.687708Z",
     "iopub.status.idle": "2025-11-09T07:03:37.693300Z",
     "shell.execute_reply": "2025-11-09T07:03:37.692497Z",
     "shell.execute_reply.started": "2025-11-09T07:03:37.687867Z"
    },
    "id": "HPIBDcf8ecqR"
   },
   "outputs": [],
   "source": [
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y = get_batch(split)\n",
    "                with ctx:\n",
    "                    logits = model(X)\n",
    "                    loss = F.cross_entropy(\n",
    "                        logits.view(-1, logits.size(-1)),\n",
    "                        Y.view(-1),\n",
    "                        ignore_index=-1\n",
    "                    )\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jf9FOKCkeoMl"
   },
   "source": [
    "## Step 6: Define SLM Training Configuration Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:37.694542Z",
     "iopub.status.busy": "2025-11-09T07:03:37.694066Z",
     "iopub.status.idle": "2025-11-09T07:03:37.964783Z",
     "shell.execute_reply": "2025-11-09T07:03:37.964025Z",
     "shell.execute_reply.started": "2025-11-09T07:03:37.694525Z"
    },
    "id": "BNmMVmiPedrs",
    "outputId": "be30f641-1ed4-4997-ac54-7235ff494a49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7eea09b1ac30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Config\n",
    "import torch\n",
    "from contextlib import nullcontext\n",
    "\n",
    "learning_rate = 1e-4\n",
    "max_iters = 20000\n",
    "warmup_steps = int(0.02 * max_iters)\n",
    "min_lr = 1e-5\n",
    "eval_iters = 500\n",
    "batch_size = 64 \n",
    "block_size = 128\n",
    "\n",
    "gradient_accumulation_steps = 16\n",
    "\n",
    "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
    "\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "torch.set_default_device(device)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:37.965958Z",
     "iopub.status.busy": "2025-11-09T07:03:37.965658Z",
     "iopub.status.idle": "2025-11-09T07:03:38.012326Z",
     "shell.execute_reply": "2025-11-09T07:03:38.011667Z",
     "shell.execute_reply.started": "2025-11-09T07:03:37.965935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "#move model to GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# activating multi-gpu if available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxcdTSGsey4c"
   },
   "source": [
    "## Step 7: Define SLM Training Configuration Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:38.013150Z",
     "iopub.status.busy": "2025-11-09T07:03:38.012982Z",
     "iopub.status.idle": "2025-11-09T07:03:40.932619Z",
     "shell.execute_reply": "2025-11-09T07:03:40.931605Z",
     "shell.execute_reply.started": "2025-11-09T07:03:38.013136Z"
    },
    "id": "lpofHzlLewHW",
    "outputId": "93e93501-2fd1-4099-dcfb-3edd3ab1a284"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/3962898220.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n",
    "\n",
    "optimizer =  torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.05, eps=1e-9)\n",
    "\n",
    "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps)\n",
    "scheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr)\n",
    "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps])\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:40.934270Z",
     "iopub.status.busy": "2025-11-09T07:03:40.933636Z",
     "iopub.status.idle": "2025-11-09T07:03:40.939525Z",
     "shell.execute_reply": "2025-11-09T07:03:40.938579Z",
     "shell.execute_reply.started": "2025-11-09T07:03:40.934239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPUs available\n",
      "GPU 0: Tesla T4\n",
      "GPU 1: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count(), \"GPUs available\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZxrYK6_fP28"
   },
   "source": [
    "## Step 8: Pre-train the SLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e6940845c8214b1b9f4c797f9d6af9e2",
      "d223fedcc4f34f64a74927c66d99c830",
      "298d1bb4c0ad4b0a821c9c060abd6136",
      "f5a8e44315944e7eb95ebc82c82915c4",
      "5d44146cf6e646c297860ac7ad461750",
      "b2d009775d7948dd86b736cbc901fa9f",
      "39439f3c58e34e51a04de3c04f4d4631",
      "1fbcf30b7957419e82df7d0682c24208",
      "5ee2135e31984703b5d3f3c83e2756a0",
      "605784751aae426a9d042b69ae93aa28",
      "4d46d6fe233f420bbc4932ffff1d5eca"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-11-09T07:03:40.940698Z",
     "iopub.status.busy": "2025-11-09T07:03:40.940358Z",
     "iopub.status.idle": "2025-11-09T09:22:29.398117Z",
     "shell.execute_reply": "2025-11-09T09:22:29.397314Z",
     "shell.execute_reply.started": "2025-11-09T07:03:40.940676Z"
    },
    "id": "AWZdt7Yve1fA",
    "outputId": "ab4c8e2c-2ab8-4d0b-fb91-56ee72db2832"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f77e3532f3046a98139157e9072bca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: train loss 9.2360, val loss 9.2339\n",
      "Current learning rate: 0.00004\n",
      "Epoch 1000: train loss 8.5250, val loss 8.5194\n",
      "Current learning rate: 0.00004\n",
      "Epoch 1500: train loss 8.0105, val loss 8.0052\n",
      "Current learning rate: 0.00005\n",
      "Epoch 2000: train loss 7.5101, val loss 7.5022\n",
      "Current learning rate: 0.00005\n",
      "Epoch 2500: train loss 7.0357, val loss 7.0315\n",
      "Current learning rate: 0.00006\n",
      "Epoch 3000: train loss 6.5715, val loss 6.5679\n",
      "Current learning rate: 0.00006\n",
      "Epoch 3500: train loss 6.1544, val loss 6.1479\n",
      "Current learning rate: 0.00007\n",
      "Epoch 4000: train loss 5.7649, val loss 5.7598\n",
      "Current learning rate: 0.00008\n",
      "Epoch 4500: train loss 5.4790, val loss 5.4739\n",
      "Current learning rate: 0.00008\n",
      "Epoch 5000: train loss 5.2900, val loss 5.2812\n",
      "Current learning rate: 0.00009\n",
      "Epoch 5500: train loss 5.1619, val loss 5.1557\n",
      "Current learning rate: 0.00009\n",
      "Epoch 6000: train loss 5.0621, val loss 5.0499\n",
      "Current learning rate: 0.00010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6500: train loss 4.9671, val loss 4.9638\n",
      "Current learning rate: 0.00010\n",
      "Epoch 7000: train loss 4.9509, val loss 4.9440\n",
      "Current learning rate: 0.00010\n",
      "Epoch 7500: train loss 4.9089, val loss 4.9033\n",
      "Current learning rate: 0.00010\n",
      "Epoch 8000: train loss 4.8981, val loss 4.8876\n",
      "Current learning rate: 0.00010\n",
      "Epoch 8500: train loss 4.8815, val loss 4.8742\n",
      "Current learning rate: 0.00010\n",
      "Epoch 9000: train loss 4.8751, val loss 4.8701\n",
      "Current learning rate: 0.00010\n",
      "Epoch 9500: train loss 4.8486, val loss 4.8487\n",
      "Current learning rate: 0.00010\n",
      "Epoch 10000: train loss 4.8605, val loss 4.8487\n",
      "Current learning rate: 0.00010\n",
      "Epoch 10500: train loss 4.8535, val loss 4.8393\n",
      "Current learning rate: 0.00010\n",
      "Epoch 11000: train loss 4.8664, val loss 4.8541\n",
      "Current learning rate: 0.00010\n",
      "⚠️ No improvement for 1/5 evals\n",
      "Epoch 11500: train loss 4.9037, val loss 4.8924\n",
      "Current learning rate: 0.00010\n",
      "⚠️ No improvement for 2/5 evals\n",
      "Epoch 12000: train loss 4.8636, val loss 4.8579\n",
      "Current learning rate: 0.00010\n",
      "⚠️ No improvement for 3/5 evals\n",
      "Epoch 12500: train loss 4.8959, val loss 4.8910\n",
      "Current learning rate: 0.00010\n",
      "⚠️ No improvement for 4/5 evals\n",
      "Epoch 13000: train loss 4.9085, val loss 4.9074\n",
      "Current learning rate: 0.00010\n",
      "⚠️ No improvement for 5/5 evals\n",
      "⏹️ Early stopping triggered at epoch 13000\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "train_loss_list, validation_loss_list = [], []\n",
    "\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(max_iters)):\n",
    "    if epoch % eval_iters == 0 and epoch != 0:\n",
    "        # Evaluate\n",
    "        losses = estimate_loss(model)\n",
    "        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        print(f\"Current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
    "        train_loss_list.append(losses['train'])\n",
    "        validation_loss_list.append(losses['val'])\n",
    "\n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            patience_counter = 0  # reset patience\n",
    "            # Save best model\n",
    "            if isinstance(model, torch.nn.DataParallel):\n",
    "                torch.save(model.module.state_dict(), best_model_params_path)\n",
    "            else:\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"⚠️ No improvement for {patience_counter}/{patience} evals\")\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"⏹️ Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    # Training batch\n",
    "    X, y = get_batch(\"train\")\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    with ctx:\n",
    "        logits = model(X)\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            y.view(-1),\n",
    "            ignore_index=-1\n",
    "        )\n",
    "        loss = loss.mean() / gradient_accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "        scaler.step(optimizer)\n",
    "        scheduler.step()\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:30:26.752608Z",
     "iopub.status.busy": "2025-11-09T09:30:26.751875Z",
     "iopub.status.idle": "2025-11-09T09:30:28.206422Z",
     "shell.execute_reply": "2025-11-09T09:30:28.205747Z",
     "shell.execute_reply.started": "2025-11-09T09:30:26.752583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully on cuda\n",
      "📝 Generated text:\n",
      "\n",
      "Once upon a time there was a pumpkin. He. She told her. She saw a little girl. One day. One day,. On the park. They didn't the. She asked do feel in the, \"Let she was that always on. She's. She knew. She in the. They. She was blue really in the dad looked, things and smiled and all and. \n",
      "\n",
      "\n",
      "\"Look,.\n",
      "Lily was. As and. He said, \"This.\n",
      "He said and said, \"Look, know, I for he went to his with then and. He picked and not. One day, the friend was very tall. She was special know know know we wasummy and looked just feel said, \"No, just, really and not and. \n",
      "\n",
      "\n",
      "John was, we the friend and quickly said, \"I.\n",
      "\n",
      "But her, and and doing around the special are a shiny. She was doing and the bear said, \"I am their friends. \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#Load model\n",
    "model = GPT(config)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "\n",
    "# handle DataParallel checkpoints automatically\n",
    "state_dict = torch.load(best_model_params_path, map_location=device)\n",
    "if any(k.startswith(\"module.\") for k in state_dict.keys()):\n",
    "    state_dict = {k[len(\"module.\"):]: v for k, v in state_dict.items()}\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"✅ Model loaded successfully on\", device)\n",
    "\n",
    "# INPUT\n",
    "sentence = \"Once upon a time there was a pumpkin.\"\n",
    "context = torch.tensor(enc.encode_ordinary(sentence), dtype=torch.long, device=device).unsqueeze(0)\n",
    "\n",
    "#Text generation or Inference\n",
    "with torch.no_grad():\n",
    "    y = model.generate(context, max_new_tokens=200, temperature=0.8, top_k=50)\n",
    "\n",
    "generated_text = enc.decode(y[0].tolist())\n",
    "print(\"📝 Generated text:\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:51:46.045391Z",
     "iopub.status.busy": "2025-11-09T09:51:46.044661Z",
     "iopub.status.idle": "2025-11-09T09:51:46.177910Z",
     "shell.execute_reply": "2025-11-09T09:51:46.177274Z",
     "shell.execute_reply.started": "2025-11-09T09:51:46.045367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGwCAYAAACHJU4LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABTUklEQVR4nO3deVhUZePG8e+w7wgKAoq4oLhi7qm9WblmmWYuqZmW7bZpVra4tlimrVpWv9IWtdTULNvU0sxMzVwyFZXcQXEFkZ15fn+Qk+SKAmeA+3Nd54KZOXPm5jTvO7fPec4ZmzHGICIiIuKEXKwOICIiInIuKioiIiLitFRURERExGmpqIiIiIjTUlERERERp6WiIiIiIk5LRUVERESclpvVAS6H3W4nISEBf39/bDab1XFERETkIhhjOHHiBBEREbi4nH/MpEQXlYSEBCIjI62OISIiIpdg7969VK5c+bzrlOii4u/vD+T9oQEBARanERERkYuRkpJCZGSk43P8fEp0UTl1uCcgIEBFRUREpIS5mGkbmkwrIiIiTktFRURERJyWioqIiIg4rRI9R0VERApHbm4u2dnZVseQUsLd3R1XV9dC2ZaKiohIGWaM4cCBAxw/ftzqKFLKlCtXjrCwsMu+zpmKiohIGXaqpISGhuLj46OLZ8plM8aQlpZGUlISAOHh4Ze1PRUVEZEyKjc311FSypcvb3UcKUW8vb0BSEpKIjQ09LIOA2kyrYhIGXVqToqPj4/FSaQ0OvW+uty5TyoqIiJlnA73SFEorPeVioqIiIg4LRUVERERcVoqKiIiUqZVrVqV119/vVC2tXTpUmw2m073LkQ66+ccsnbs4cSRLMq3iLY6ioiI/Mc111zDFVdcUSgFY82aNfj6+l5+KCkSGlE5i4/6/UDFmv481Xe31VFEROQSGGPIycm5qHVDQkJ05pMTU1E5i8qtqnCcIOb93ZCcE+lWxxERKR7GwMmT1izGXHTMgQMHsmzZMt544w1sNhs2m41p06Zhs9n49ttvadKkCZ6envzyyy/Ex8fTtWtXKlasiJ+fH82aNWPx4sX5tvffQz82m43/+7//4+abb8bHx4eaNWuyYMGCS96tX3zxBfXq1cPT05OqVasyceLEfI+//fbb1KxZEy8vLypWrEiPHj0cj82ZM4cGDRrg7e1N+fLladeuHSdPnrzkLCWRispZtLknhgouRzhMBZZN/N3qOCIixSMtDfz8rFnS0i465htvvEHLli25++67SUxMJDExkcjISACGDx/OSy+9xJYtW4iNjSU1NZXOnTuzZMkS1q1bR6dOnejSpQt79uw572uMGTOGXr16sXHjRjp37ky/fv04evRogXfp2rVr6dWrF7feeit//vkno0ePZsSIEUybNg2A33//nYcffpixY8cSFxfHd999x9VXXw1AYmIiffr04c4772TLli0sXbqU7t27YwpQ6koFU4IlJycbwCQnJxf6tu9usNKAMffWWFTo2xYRcQbp6elm8+bNJj09Pe+O1FRj8sY2in9JTS1Q9jZt2phHHnnEcfunn34ygJk/f/4Fn1uvXj3z1ltvOW5HRUWZ1157zXEbMM8++6zjdmpqqgHMt99+e8Ftn8px7NgxY4wxffv2Ne3bt8+3zuOPP27q1q1rjDHmiy++MAEBASYlJeWMba1du9YAZteuXRd8XWd0xvvrNAX5/NaIyjn0uKscAHPjG5KbqsM/IlIG+PhAaqo1SyHNEWnatGm+26mpqQwbNow6depQrlw5/Pz82LJlywVHVGJjYx2/+/r6EhAQ4PjumoLYsmULrVu3zndf69at2b59O7m5ubRv356oqCiqV69O//79mT59Omn/jC41bNiQtm3b0qBBA3r27Mn777/PsWPHCpyhpFNROYdr74sh2OUYhwjh51d1+EdEygCbDXx9rVkK6Sqm/z17Z9iwYcybN48XX3yR5cuXs379eho0aEBWVtZ5t+Pu7v6fXWPDbrcXSsbT+fv788cffzBz5kzCw8MZOXIkDRs25Pjx47i6urJo0SK+/fZb6taty1tvvUVMTAw7d+4s9BzOTEXlHNw9bHSrsw2AOZ9qREVExJl4eHiQm5t7wfVWrFjBwIEDufnmm2nQoAFhYWHs2rWr6AP+o06dOqxYseKMTLVq1XJ8UZ+bmxvt2rVj/PjxbNy4kV27dvHjjz8CeQWpdevWjBkzhnXr1uHh4cG8efOKLb8z0HVUzqPnoAA+HApf7GjIm6npuPp5Wx1JRETIO1Nn1apV7Nq1Cz8/v3OOdtSsWZO5c+fSpUsXbDYbI0aMKJKRkXN57LHHaNasGc899xy9e/dm5cqVTJo0ibfffhuAr7/+mr///purr76aoKAgvvnmG+x2OzExMaxatYolS5bQoUMHQkNDWbVqFYcOHaJOnTrFlt8ZaETlPNoOrk2Qy3EOmoqseEOHf0REnMWwYcNwdXWlbt26hISEnHPOyauvvkpQUBCtWrWiS5cudOzYkcaNGxdbzsaNGzNr1iw+++wz6tevz8iRIxk7diwDBw4EoFy5csydO5frrruOOnXqMGXKFGbOnEm9evUICAjg559/pnPnztSqVYtnn32WiRMncv311xdbfmdgM6bknueUkpJCYGAgycnJBAQEFMlr3FFvNdM2N+fBWt/zVlzHInkNERErZGRksHPnTqpVq4aXl5fVcaSUOd/7qyCf3xpRuYCed/oD8MX2WOxpGRanERERKVtUVC6g3eAYAm3JJJpwfn1jjdVxRETEQvfddx9+fn5nXe677z6r45VKmkx7AR5eLnStvY2PtzRj9kdpXPWU1YlERMQqY8eOZdiwYWd9rKimIJR1KioXocdAPz5+Er7YVp/X0jJw8dGxXBGRsig0NJTQ0FCrY5QpOvRzETo8FIO/7QT7TSV+e0uHf0RERIqLpUXlxIkTPProo0RFReHt7U2rVq1Ys8b5ioCntws31YoDYM60VIvTiIiIlB2WFpW77rqLRYsW8cknn/Dnn3/SoUMH2rVrx/79+62MdVY9B+ZdlnlOXH3s6ZkWpxERESkbLCsq6enpfPHFF4wfP56rr76a6OhoRo8eTXR0NO+8845Vsc6p48Mx+NlS2WsiWT1ptdVxREREygTLikpOTg65ublnXATG29ubX3755azPyczMJCUlJd9SXLx8XOhS89ThnxPF9roiIiJlmWVFxd/fn5YtW/Lcc8+RkJBAbm4un376KStXriQxMfGszxk3bhyBgYGOJTIyslgz9xyQ9zXkc7bUw2To8I+ISElVtWpVXn/9dcdtm83G/Pnzz7n+rl27sNlsrF+//rJet7C2UxAX+tucnaVzVD755BOMMVSqVAlPT0/efPNN+vTpg4vL2WM99dRTJCcnO5a9e/cWa95Oj8TgazvJbhPF72/r8I+ISGmRmJhY6N+hM3DgQLp165bvvsjISBITE6lfv36hvlZpZmlRqVGjBsuWLSM1NZW9e/eyevVqsrOzqV69+lnX9/T0JCAgIN9SnLx9XbgxeisAsz8svsNOIiJStMLCwvD09Czy13F1dSUsLAw3N13G7GI5xXVUfH19CQ8P59ixY3z//fd07drV6kjn1KP/P4d/Nuvwj4iULsbAyZPWLAX5etz33nuPiIgI7HZ7vvu7du3KnXfeSXx8PF27dqVixYr4+fnRrFkzFi9efN5t/vfwyOrVq2nUqBFeXl40bdqUdevW5Vs/NzeXQYMGUa1aNby9vYmJieGNN95wPD569Gg++ugjvvzyS2w2GzabjaVLl5710M+yZcto3rw5np6ehIeHM3z4cHJychyPX3PNNTz88MM88cQTBAcHExYWxujRoy9+h/3Hn3/+yXXXXYe3tzfly5fnnnvuITX130tvLF26lObNm+Pr60u5cuVo3bo1u3fvBmDDhg1ce+21+Pv7ExAQQJMmTfj9998vOcvFsLSofP/993z33Xfs3LmTRYsWce2111K7dm3uuOMOK2OdV+chMfjY0thpqvLHu853zRcRkUuVlgZ+ftYsaWkXn7Nnz54cOXKEn376yXHf0aNH+e677+jXrx+pqal07tyZJUuWsG7dOjp16kSXLl3Ys2fPRW0/NTWVG2+8kbp167J27VpGjx59xmXz7XY7lStXZvbs2WzevJmRI0fy9NNPM2vWLACGDRtGr1696NSpE4mJiSQmJtKqVaszXmv//v107tyZZs2asWHDBt555x0++OADnn/++XzrffTRR/j6+rJq1SrGjx/P2LFjWbRo0cXvtH+cPHmSjh07EhQUxJo1a5g9ezaLFy/mwQcfBPJOdOnWrRtt2rRh48aNrFy5knvuuQebzQZAv379qFy5MmvWrGHt2rUMHz4cd3f3AucoEGOhzz//3FSvXt14eHiYsLAwM3jwYHP8+PGLfn5ycrIBTHJychGmPFOPGn8YMObJ+l8X6+uKiBSm9PR0s3nzZpOenm6MMSY11Zi8sY3iX1JTC5a9a9eu5s4773Tcfvfdd01ERITJzc096/r16tUzb731luN2VFSUee211xy3ATNv3jzHtsqXL+/YL8YY88477xjArFu37pyZBg8ebG655RbH7QEDBpiuXbvmW2fnzp35tvP000+bmJgYY7fbHetMnjzZ+Pn5Of6WNm3amKuuuirfdpo1a2aefPLJc2Y53el/23vvvWeCgoJM6mk7fOHChcbFxcUcOHDAHDlyxABm6dKlZ92Wv7+/mTZt2kW97n/fX6cryOe3pSMqvXr1Ij4+nszMTBITE5k0aRKBgYFWRrooPW/LO445Z3MdTGaWxWlERAqHjw+kplqz+PgULGu/fv344osvyMzMOwQ/ffp0br31VlxcXEhNTWXYsGHUqVOHcuXK4efnx5YtWy56RGXLli3Exsbmu3xGy5Ytz1hv8uTJNGnShJCQEPz8/Hjvvfcu+jVOf62WLVs6RiwAWrduTWpqKvv27XPcFxsbm+954eHhJCUlFei1Tr1ew4YN8fX1zfd6druduLg4goODGThwIB07dqRLly688cYb+c7EHTp0KHfddRft2rXjpZdeIj4+vsAZCsop5qiUNJ2HxOBNOvH26qx/X4d/RKR0sNnA19ea5bTP6YvSpUsXjDEsXLiQvXv3snz5cvr16wfkHXaZN28eL774IsuXL2f9+vU0aNCArKzC+4flZ599xrBhwxg0aBA//PAD69ev54477ijU1zjdfw+v2Gy2M+boFJapU6eycuVKWrVqxeeff06tWrX47bffgLy5N3/99Rc33HADP/74I3Xr1mXevHlFkuMUFZVL4BfoyvXV/7n42/vHLE4jIlL2eHl50b17d6ZPn87MmTOJiYmhcePGAKxYsYKBAwdy880306BBA8LCwti1a9dFb7tOnTps3LiRjIwMx32nPqhPWbFiBa1ateKBBx6gUaNGREdHnzG64OHhQW5u7gVfa+XKlZjTZhOvWLECf39/KleufNGZL1adOnXYsGEDJ0+ezPd6Li4uxMTEOO5r1KgRTz31FL/++iv169dnxowZjsdq1arFkCFD+OGHH+jevTtTp04t9JynU1G5RD37eQAwe1NtTFa2xWlERMqefv36sXDhQj788EPHaApAzZo1mTt3LuvXr2fDhg307du3QKMPffv2xWazcffdd7N582a++eYbJkyYkG+dmjVr8vvvv/P999+zbds2RowYccaX6latWpWNGzcSFxfH4cOHyc4+87PigQceYO/evTz00ENs3bqVL7/8klGjRjF06NBzXlPscvTr1w8vLy8GDBjApk2b+Omnn3jooYfo378/FStWZOfOnTz11FOsXLmS3bt388MPP7B9+3bq1KlDeno6Dz74IEuXLmX37t2sWLGCNWvWUKdOnULPeToVlUt0w9AYPMlguz2aPz9YZXUcEZEy57rrriM4OJi4uDj69u3ruP/VV18lKCiIVq1a0aVLFzp27OgYbbkYfn5+fPXVV/z55580atSIZ555hpdffjnfOvfeey/du3end+/etGjRgiNHjvDAAw/kW+fuu+8mJiaGpk2bEhISwooVK854rUqVKvHNN9+wevVqGjZsyH333cegQYN49tlnC7g3Lo6Pjw/ff/89R48epVmzZvTo0YO2bdsyadIkx+Nbt27llltuoVatWtxzzz0MHjyYe++9F1dXV44cOcLtt99OrVq16NWrF9dffz1jxowpkqyn2Mzp400lTEpKCoGBgSQnJxf7xd8Abq6+nvk7r+DZhl/x3Pouxf76IiKXIyMjg507d1KtWrUzvndN5HKd7/1VkM9vjahchh59/jn886cO/4iIiBQFFZXL0GVYDB5kEmevyV9T9d0/IiJSvKZPn46fn99Zl3r16lkdr1DoywYuQ0CQKx2j/uKr3bHMfvcI9e+1OpGIiJQlN910Ey1atDjrY0V+xdhioqJymXr2ceOrl2DOxlqMyc6GUvLGEBER5+fv74+/v7/VMYqUDv1cppuG1cKdLDbn1mbzNB3+EZGSp6guHCZlW2G9rzSicpkCy7vRocpGFu6JZc6Uw4y82+pEIiIXx8PDAxcXFxISEggJCcHDwyPfpdxFLoUxhqysLA4dOoSLiwseHh6XtT0VlULQ81ZXFo6H2RtqMlKHf0SkhHBxcaFatWokJiaSkJBgdRwpZXx8fKhSpcplX7hO11EpBMcO5VAx1E42Hmz5vxXUHtTasiwiIgVljCEnJ+eCl3sXuViurq64ubmdc4SuIJ/fGlEpBEEhbrSL/JNv9zZgzjuHeHaQ1YlERC6ezWbD3d291JwlIqWLJtMWkh69XAGYvT4acnIsTiMiIlI6qKgUkm5P1MKNbDbm1mfbpzr7R0REpDCoqBSS4FA3rqu0DYA5bydZnEZERKR0UFEpRD175U0amvNHdR3+ERERKQQqKoWo2xO1cCWHdbmxxM/U4R8REZHLpaJSiCqEuXFtRN7hn9mTDlqcRkREpORTUSlkPXvmXZZmzh/VdPhHRETkMqmoFLJuj9fChVzW5lzB35/p8I+IiMjlUFEpZKGV3LkmPO/wzxeTD1icRkREpGRTUSkCPW7JO/wz+/dqoEtSi4iIXDIVlSLQ/cma2LCzJqcRu2etsjqOiIhIiaWiUgQqVnbn6rB/Lv72VqLFaUREREouFZUi0rO7HYDZv1fV4R8REZFLpKJSRE4d/lmV3YQ9c3T2j4iIyKVQUSki4VXcuaridgC+eGu/xWlERERKJhWVInTq8M8nK2tiklMsTiMiIlLyqKgUoT6jY/C2pbPO3pClw7+zOo6IiEiJo6JShCqEunDHNTsBGD81BLKyLE4kIiJSsqioFLGhk2rgQi7fZV7LxvEaVRERESkIFZUiVqOuJ7c0yLumyoSJgDHWBhIRESlBVFSKweOvVwZg5vHr2fvJUkuziIiIlCQqKsWg2XX+XFN5Bzm48/qzh6yOIyIiUmKoqBSTJ14IBOC9vddz/Kd1FqcREREpGVRUikmn/iHUL7eXVPyZ8sgWq+OIiIiUCCoqxcRmg8eH5U2kfePPa8nc8rfFiURERJyfikoxuvXxKlTyPMwBwvl08Eqr44iIiDg9FZVi5OEBQwYeA2DC0ibYkw5bnEhERMS5qagUs7tfjibAJZWtpjZfP7LI6jgiIiJOTUWlmAUE2rjvhr0AvDKnGqSlWZxIRETEeamoWOCRSTVxJ4tfcq5k5chvrY4jIiLitFRULBBRxY3brtwBwCtT/CA31+JEIiIizklFxSLD3qoKwPyT7dk2WXNVREREzkZFxSJ1m/pwY804DC5MfD5NX1YoIiJyFioqFnpiYkUAPjrUmYPzdV0VERGR/1JRsdBVN5ajRehOMvHircf3WB1HRETE6aioWMhmgydGegHwdnwHUtfoO4BEREROp6Jisa73hRPtm8gxgvngQX2rsoiIyOlUVCzm6grDHswA4NXVrcnetd/iRCIiIs5DRcUJ3D6qGiHux9hDFLMfXGZ1HBEREaehouIEvL3h4d5JALzybT3M8WSLE4mIiDgHFRUncf+rNfGxpbHe3pDFj39vdRwRERGnoKLiJMqHuHBX210AvPJJRcjKsjaQiIiIE1BRcSJDJkfjSg6LMtuwbtx3VscRERGxnIqKE6lay4NeV2wDYMJrLmC3W5xIRETEWioqTubxNyIB+Dy5E7s/WmptGBEREYupqDiZRlf70y5qG7m48dqIo1bHERERsZSKihN6/IUgAN7ffz1HF621OI2IiIh1VFScUPu+ITQM2kMavrwzZJvVcURERCyjouKEbDZ4/AkbAG/+dR0Zf8VbnEhERMQaKipOqtdjkVTxSiKJinw8+Der44iIiFhCRcVJubvDkEEpAEz4uTm5Bw5ZnEhERKT4qag4sbvG1SDINZntpiYLHllsdRwREZFiZ2lRyc3NZcSIEVSrVg1vb29q1KjBc889hzHGylhOw8/fxv03JQAwfm40JvWkxYlERESKl6VF5eWXX+add95h0qRJbNmyhZdffpnx48fz1ltvWRnLqTz0Vi08yOS3nGasGKHL6ouISNliaVH59ddf6dq1KzfccANVq1alR48edOjQgdWrV591/czMTFJSUvItpV1YJVcGtN4BwPh3AyEnx+JEIiIixcfSotKqVSuWLFnCtm151wrZsGEDv/zyC9dff/1Z1x83bhyBgYGOJTIysjjjWmbY2zWwYeer9HZsmqBRFRERKTssLSrDhw/n1ltvpXbt2ri7u9OoUSMeffRR+vXrd9b1n3rqKZKTkx3L3r17izmxNWrFetG9Xl6ZG/+yXV9WKCIiZYalRWXWrFlMnz6dGTNm8Mcff/DRRx8xYcIEPvroo7Ou7+npSUBAQL6lrHjyzUoAzDjemd1Tf7Q4jYiISPGwGQtPsYmMjGT48OEMHjzYcd/zzz/Pp59+ytatWy/4/JSUFAIDA0lOTi4TpaVd1e0s2V2Th8Jm82ZCj7xL2IqIiJQwBfn8tnREJS0tDReX/BFcXV2x69DGWQ0fXx6A/ztwA4e+0tVqRUSk9LO0qHTp0oUXXniBhQsXsmvXLubNm8err77KzTffbGUsp9W2ZzBNQ3aRjg9vDd1pdRwREZEiZ+mhnxMnTjBixAjmzZtHUlISERER9OnTh5EjR+Lh4XHB55e1Qz8AX7x9kB6DKxLEUXYv34v/VQ2tjiQiIlIgBfn8trSoXK6yWFRyc6FuUALbTkQwoeEnPLa+v9WRRERECqTEzFGRgnN1hSeG5gLw6obryPxrh8WJREREio6KSgl021ORRHgeIYFKfHr/CqvjiIiIFBkVlRLI0xOG3pX39QHjl7ckd2+CxYlERESKhopKCXXPuGoEuaWwjVrMH7zI6jgiIiJFQkWlhPL3hwd7HATgpYX1MUeOWpxIRESk8KmolGAPvRGNty2d3+1N+PGxhVbHERERKXQqKiVYSKiNuzrkfTHjuBlV4ORJixOJiIgULhWVEu6xydVxJYcl2W1YM/Irq+OIiIgUKhWVEi6qhht9W/wNwMvv+ENWlsWJRERECo+KSinwxOQoAOamX0/cxK8tTiMiIlJ4VFRKgfpNPOlSZwcGF1552Q769mkRESklVFRKiafeDAfg4+Sb2P/BdxanERERKRwqKqVEy3a+XF1lJ9l48NqIo1Byv2tSRETEQUWlFBn+cjAA7x7sytH5P1ucRkRE5PKpqJQinXoHElt+P6n4M3nY31bHERERuWwqKqWIzQbDR3oA8MbfXTj581qLE4mIiFweFZVSpucDIVTzS+IIFfjwoXVWxxEREbksKiqljJsbPD4kF4AJG9uTvXGLxYlEREQunYpKKXTH0+FU9DzGHqL47MHlVscRERG5ZCoqpZCXFzw66AQALy9vhX3XHosTiYiIXBoVlVLq/herEOCayl/UZ+FDugCciIiUTCoqpVRgINzf4xAA476JxSQdsjiRiIhIwamolGKPvFoVT1smK+1XsvzxBVbHERERKTAVlVIsPMLGwHb7AXhpRhU4ccLiRCIiIgWjolLKPT4pChdy+TanPRtGzbU6joiISIGoqJRyNWq50qv5bgBeficAMjMtTiQiInLxVFTKgCcnRQLwecZN/D1BoyoiIlJyqKiUAVc0c6dT7V3YcWXCeDvk5lodSURE5KKoqJQRw18LBeDDlFs48H9fW5xGRETk4qiolBFXd/Thysp7ycSL10ccAbvd6kgiIiIXpKJSRthsMHxcOQDePtSDo9O/tTaQiIjIRVBRKUO69PWnYWgiJwjg1ccTwBirI4mIiJyXikoZ4uICo17xA+DNg7058qlGVURExLmpqJQxXW/zp2FoAicI4DWNqoiIiJNTUSljXFxg9D+jKm8c7M2RGd9bnEhEROTcVFTKoK79A7giNIFU/Hn1sf0aVREREaelolIG2WwwarwvAG8e7MXhGT9YnEhEROTsVFTKqK63B3JF6P68UZVhmqsiIiLOSUWljLLZ/p2r8taBHhyeucjiRCIiImdSUSnDbuofSKN/RlUmPqZRFRERcT4qKmVY3qhK3lyVtw704PDnSyxOJCIikp+KShnXpX85Gofu4yR+TByqM4BERMS5qKiUcTYbjJ7wz6hK4i0c+vxHixOJiIj8S0VFuPG2IBqH7s0bVdF1VURExImoqEi+M4AmJXTn0KyfLE4kIiKSR0VFALixfxBN/hlVmTBUZwCJiIhzUFER4NRclVOjKjdzaM4yixOJiIioqMhpbrgtiKahe0jDl1ce1VwVERGxnoqKOJw+qjI5oRtJc362OJGIiJR1KiqST+fbgh2jKhOGaFRFRESspaIi+Zx+tdrJ+7uS9MVyixOJiEhZpqIiZ+jcvzzNQndrroqIiFhORUXOcMaoyrwVFicSEZGySkVFzur6/hVoHrqLdHwY/8g+q+OIiEgZpaIiZ3X6GUBv77uJg3M1qiIiIsXvkorK3r172bfv339lr169mkcffZT33nuv0IKJ9TrdVoEWFXeSjg+vaFRFREQscElFpW/fvvz0U973wRw4cID27duzevVqnnnmGcaOHVuoAcU6p38H0Nv7unBg7q8WJxIRkbLmkorKpk2baN68OQCzZs2ifv36/Prrr0yfPp1p06YVZj6xWMfbQmgR+s+oyqMaVRERkeJ1SUUlOzsbT09PABYvXsxNN90EQO3atUlMTCy8dGK5088AemfvjRyY/5vFiUREpCy5pKJSr149pkyZwvLly1m0aBGdOnUCICEhgfLlyxdqQLFex/6hXBn6d94ZQA9rVEVERIrPJRWVl19+mXfffZdrrrmGPn360LBhQwAWLFjgOCQkpUf+UZUbOPDlKosTiYhIWWEz5tIuO5qbm0tKSgpBQUGO+3bt2oWPjw+hoaGFFvB8UlJSCAwMJDk5mYCAgGJ5zbLKGGgV9je/JVXn0cgveG3PLVZHEhGREqogn9+XNKKSnp5OZmamo6Ts3r2b119/nbi4uGIrKVK8bDYY84oPAFP2dibxy9UWJxIRkbLgkopK165d+fjjjwE4fvw4LVq0YOLEiXTr1o133nmnUAOK82jfP4yWofFk4K25KiIiUiwuqaj88ccf/O9//wNgzpw5VKxYkd27d/Pxxx/z5ptvFmpAcR6nz1WZsud6Er/63eJEIiJS2l1SUUlLS8Pf3x+AH374ge7du+Pi4sKVV17J7t27L3o7VatWxWaznbEMHjz4UmJJMWjfP4xWoTvIwJuXHtxrdRwRESnlLqmoREdHM3/+fPbu3cv3339Phw4dAEhKSirQpNY1a9aQmJjoWBYtWgRAz549LyWWFIPTR1Xe3XM9CV+usTiRiIiUZpdUVEaOHMmwYcOoWrUqzZs3p2XLlkDe6EqjRo0uejshISGEhYU5lq+//poaNWrQpk2bS4klxaRd/3CuqridTLx48cH9VscREZFS7JJPTz5w4ACJiYk0bNgQF5e8vrN69WoCAgKoXbt2gbeXlZVFREQEQ4cO5emnnz7rOpmZmWRmZjpup6SkEBkZqdOTLfDTzANc1zcMDzLZ/vk6qvS60upIIiJSQhT56ckAYWFhNGrUiISEBMc3KTdv3vySSgrA/PnzOX78OAMHDjznOuPGjSMwMNCxREZGXtJryeW7tk8Y10RsIwtPXnz0YN6FVkRERArZJRUVu93O2LFjCQwMJCoqiqioKMqVK8dzzz2H3W6/pCAffPAB119/PREREedc56mnniI5Odmx7N2ryZxWGvtmOQA+SOzMzun6ZmURESl8bpfypGeeeYYPPviAl156idatWwPwyy+/MHr0aDIyMnjhhRcKtL3du3ezePFi5s6de971PD09HV+GKNb73y2htI/cyqK9tXn+saN80M/kzbYVEREpJJc0RyUiIoIpU6Y4vjX5lC+//JIHHniA/fsLNsFy9OjRvPvuu+zduxc3t4vvTrqEvvV++/owLbtUwJUctn64kug7/md1JBERcXJFPkfl6NGjZ52LUrt2bY4ePVqgbdntdqZOncqAAQMKVFLEOVx5YwU6V9tMLm6MffyE5qqIiEihuqSi0rBhQyZNmnTG/ZMmTSI2NrZA21q8eDF79uzhzjvvvJQo4gTGvFMRgOlHOrL13WUWpxERkdLkkg79LFu2jBtuuIEqVao4rqGycuVK9u7dyzfffOO4vH5R06Ef59G15l8s2FGPPkHfMeNIR81VERGRcyryQz9t2rRh27Zt3HzzzRw/fpzjx4/TvXt3/vrrLz755JNLCi0l25j38s7W+uxYBza9+aPFaUREpLS45Au+nc2GDRto3Lgxubm5hbXJ89KIinPpUWcTX2ytT4/AH5h9tB24XPJlekREpBQrlgu+ifzX6P+LxIadOckd2PDqEqvjiIhIKaCiIoWmfutAetf/C4DRY21QTCNrIiJSeqmoSKEa9UEULuQy/0Q71r682Oo4IiJSwhXowiXdu3c/7+PHjx+/nCxSCtRuHkDfhn/y6YYGjHrRk6+fzAVXV6tjiYhICVWgEZXTvxDwbEtUVBS33357UWWVEmLk1Gq4ksPCk9ew6rkfrI4jIiIlWKGe9VPcdNaP87qz6Uamro2lg/dyvk9pCbrqsIiI/ENn/YjlRkyrgRvZ/JD+P34Z8b3VcUREpIRSUZEiUa2+L3deuRmAUa+Xg+xsawOJiEiJpKIiReaZabVwJ4sfM1qz9CmNqoiISMGpqEiRqRLjzd1XbQFg5KQQTEamxYlERKSkUVGRIvX01Fp4ksHyzBYseVKjKiIiUjAqKlKkKkV7c981cQCMnBKBSc+wOJGIiJQkKipS5IZPq423LZ2VWU35bohGVURE5OKpqEiRC4vyZHC7bQCM/CAKczLN4kQiIlJSqKhIsXhiah18bSf5PecKvn5YV6sVEZGLo6IixSKkkgcPXb8DgJEf18B+4qTFiUREpCRQUZFiM+yDuvjbUlmf04D5gzWqIiIiF6aiIsWmfJg7j94UD8CoGTHYk09YnEhERJydiooUqyHv1yPQJYVNuXWZfe8iq+OIiIiTU1GRYhUU4sZj3XcBMHp2PXKPJlsbSEREnJqKihS7R96rR5BLMlvtMXx29xKr44iIiBNTUZFiFxDkyuO99wAwZn4sOYeOWZxIRESclYqKWOKhKfWo4HqU7fZoPh30k9VxRETESamoiCX8Alx4st9+AMZ83ZjMXYkWJxIREWekoiKWeeDt+kS4H2KXqcpbvZZbHUdERJyQiopYxsfXxotP5p3189yajhz68U+LE4mIiLNRURFL9R8TTeOgnaQQyJj+O8AYqyOJiIgTUVERS7m4wMS3vQGYktCFLZN0urKIiPxLRUUsd82tYXSttZlc3Hh8uCtkZVkdSUREnISKijiF8TOr4EY2C9OuZfHDC6yOIyIiTkJFRZxCrcZ+DG4XB8Bj79cm9+BhixOJiIgzUFERpzFyRh2CXJPZaK/PtD7fWx1HREScgIqKOI3gEFdG3psEwLM/XceJNVstTiQiIlZTURGn8sBrNYn2TeAA4Yzvu87qOCIiYjEVFXEqHh4w/uW83yfs6MbeT5dZG0hERCyloiJOp9sDEVxdaQcZePP0gymQk2N1JBERsYiKijgdmw1e/SQUgE+Tu7Dm2S8tTiQiIlZRURGn1OTaAG5vvgWAoRMrYY4nW5xIRESsoKIiTuuFz6LxtqXzS86VzBuoURURkbJIRUWcVuVq7gzrvQ+AJ75sTeaWvy1OJCIixU1FRZzaE+9FE+ZxhHhqMLn3z1bHERGRYqaiIk7Nz9/GC8+kAzD2z24cXvCrxYlERKQ4qaiI0xvwTGUalt9LMuUYe9cesNutjiQiIsVERUWcnqsrTJziB8Dbh3qwdby+XVlEpKxQUZESoW2PIG6svYNc3HhitA+cPGl1JBERKQYqKlJivPJZJK7k8FVmB358YI7VcUREpBioqEiJUbuhJ/d32gnAY59cQe7ufRYnEhGRoqaiIiXKqI+jCXQ9wXrTkI/7fGt1HBERKWIqKlKiVAixMeLBYwA8s/IGUpettTiRiIgUJRUVKXEefLkK1f0OkkgEr/TfAMZYHUlERIqIioqUOJ6e8PIENwBe2Xsr+95daHEiEREpKioqUiLdck95WkfuJh0fnhmWCRkZVkcSEZEioKIiJZLNBq9+EgrAxydv4ffHP7c4kYiIFAUVFSmxmrfxpl/LeAAee6cG5mCSxYlERKSwqahIifbijGp42TL4Ofcqvrz9C6vjiIhIIVNRkRKtSlUXht6WN5Iy7If2ZPz6h8WJRESkMKmoSIk3fHIVwr2OEU80r/Rao29XFhEpRVRUpMTz94dXX827lsoL+wcQP04Ta0VESgsVFSkVet8XzHU195CJFw+PKY85dNjqSCIiUghUVKRUsNlg8twI3G3ZfJPdgS/7fGZ1JBERKQQqKlJq1K7vxuO3HQDg4SU3cfLHVRYnEhGRy6WiIqXKM1MiifI9zF6q8FyfzZCTY3UkERG5DCoqUqr4+MCbb+d9D9DEpNvYPFKHgERESjIVFSl1brq9HF0a7CIHdwaPr4JJPGB1JBERuUSWF5X9+/dz2223Ub58eby9vWnQoAG///671bGkhHtjbiTeLhkszb2aGT3mWh1HREQukaVF5dixY7Ru3Rp3d3e+/fZbNm/ezMSJEwkKCrIylpQC1aJdeeaevFOUH/u1O8e//sXiRCIicilsxhhj1YsPHz6cFStWsHz58otaPzMzk8zMTMftlJQUIiMjSU5OJiAgoKhiSgmVmQmxFQ+yLbkiDwV/ypsHeoO7u9WxRETKvJSUFAIDAy/q89vSEZUFCxbQtGlTevbsSWhoKI0aNeL9998/5/rjxo0jMDDQsURGRhZjWilpPD1h8ofeAEw+2oc/hs2wOJGIiBSUpSMqXl5eAAwdOpSePXuyZs0aHnnkEaZMmcKAAQPOWF8jKnIp+rT4m89WV6eFy2p+3RmBS5XKVkcSESnTCjKiYmlR8fDwoGnTpvz666+O+x5++GHWrFnDypUrL/j8gvyhUnYl7LNTu2o6J3J9ea/xFO5ee5/VkUREyrQSc+gnPDycunXr5ruvTp067Nmzx6JEUhpFVHZh7JDjADz5Ry8OzfrJ2kAiInLRLC0qrVu3Ji4uLt9927ZtIyoqyqJEUlo9OK4SsRX2c4xght99OG+mrYiIOD1Li8qQIUP47bffePHFF9mxYwczZszgvffeY/DgwVbGklLIzQ3emVEOgA9TevLrQzOtDSQiIhfF0qLSrFkz5s2bx8yZM6lfvz7PPfccr7/+Ov369bMylpRSrdr7cuc18QDc/3+Nydm+0+JEIiJyIZZOpr1cmkwrBXX4kCEmIoWjOYG8Vvd9Hv3rbqsjiYiUOSVmMq1IcasQYuOlEWkAjNzcm4Sp31ucSEREzkdFRcqcQc+G0yJ8DycI4LEHMyEtzepIIiJyDioqUua4uMDbs0NwIZfP0m5i8d2fWx1JRETOQUVFyqTGrb0Z3DlvMu3gGa3J3LTd4kQiInI2KipSZj03vQYVPY6yjVpMvHk5lNx55SIipZaKipRZgeVsTByXDcBzO/qw8+1vLE4kIiL/paIiZVrfIRW5pupOMvDmkWHucOKE1ZFEROQ0KipSptls8PbccNzI5quMDizoP9vqSCIichoVFSnz6jTy4rEeeV+E+fCX15G25i+LE4mIyCkqKiLAiGk1iPQ+xG6q8kL3tZCTY3UkERFBRUUEAF9fePONvN9f3teXJb3etTaQiIgAKioiDl3vCqF/m93k4kbPeX3Y8eIsqyOJiJR5Kioi/7DZ4L3vomhReR/HCKbLM7Ekf7PC6lgiImWaiorIaby8YN6qSlTyPsJWatOnWzq58busjiUiUmapqIj8R3iEjS8X+eBty+Db7HYMv3Kprq8iImIRFRWRs2jS2pupk04CMOHwQD5q8yHY7RanEhEpe1RURM6h9wPleXbgPgDuWXcfv97xvsWJRETKHhUVkfMY80Flbm6yhyw8ufnjbux560urI4mIlCkqKiLn4eICHy+tQmxIAklUpOsjUZz8ea3VsUREygwVFZEL8PODBb9VJMTjOOvNFQzsmIh9X4LVsUREygQVFZGLEFXdlbkL3HEnmzkZN/Jci68hPd3qWCIipZ6KishFuqqjL1NeOg7A6IR7mN3hPTDG2lAiIqWciopIAdz5ZAhDeuwFYMAvd7PukWnWBhIRKeVUVEQKaPzMSDrW3UM6PnR9qy0HPvre6kgiIqWWiopIAbm5wWcrqhBT7gB7qUL3O8uRuXaT1bFEREolFRWRS1CuHCz4pTzl3E6w0t6Ce9tsxSQdsjqWiEipo6Iicolq1XNn1mcGV3L46GQPXm05C7KyrI4lIlKqqKiIXIb2twTw6lOHAXj87/v5puu7OhNIRKQQqaiIXKaHXgjj7o57MLjQ57vb2TJihtWRRERKDRUVkctks8GkBVW4uvpeUgikywstODJ3mdWxRERKBRUVkULg4QFzVlamqt8h4ommV2/I3rzd6lgiIiWeiopIIQkJtbFgaSB+Lif5MacND7Vcg31LnNWxRERKNBUVkULUoIkHn36QhQ0776b05ZbYbZz4/BurY4mIlFgqKiKFrOvAID566wQetizm53Sh1a2R/P3om2C3Wx1NRKTEUVERKQL9Hwxk2c8uhPkks4kGNHujHz9ePRpSUqyOJiJSoqioiBSRK69y4/dtgTSrdoijlKfDipFMqvUGZqvmrYiIXCwVFZEiVKkSLPsrhNs6HSYXNx46OIJ7Yn8ja95Cq6OJiJQIKioiRczbGz7+pgKvjDyBC7n8X/YAruseyMEnX9W8FRGRC1BRESkGNhsMG+PPwgV2Aj3SWMFVNB3fkz/aPg4nTlgdT0TEaamoiBSjTl3cWbXRh5iw4+wjkquWPsdntUfDtm1WRxMRcUoqKiLFLCYGVm0tx/Utj5OOD30SJvJ0g6+wf6V5KyIi/6WiImKBwED4ank5nhicCsC4rMfoepOdlGfHa96KiMhpVFRELOLqCi9P8uPTaTl4uWbxNV248oUb2d7pIc1bERH5h4qKiMX6DXBj+W8eVAo6yRbq0nzR8yyqPwS260sNRURUVEScQNOmsOYvX66sf4LjBNFpz7u8FjsVs1DfEyQiZZuKioiTCA+Hpb/7c8etadhxZWjGi9x540Eyn30OMjKsjiciYgkVFREn4ukJH8zw4fUJObjY7EzjDlq90JllVfrDxx9Dbq7VEUVEipWKioiTsdngkcfc+P4HF4J8M/mDJlxzaDbXDwhhfZ0+8O23YIzVMUVEioWKioiTatcONu/w5IF7cnBzyeU7rqfR9ln07XyMHS37w++/Wx1RRKTIqaiIOLGwMJj8rhtbt7nS95ZMAGbSlzqrpvJAs9Ukdrsf4uMtTikiUnRUVERKgBo1YPocT9atg+uvSScHd97hAWp8OZGna83h+L1PwqFDVscUESl0KioiJcgVV8A3P3mzdCm0jD1JOj6Msz9J9feeZHzlN0kf/TKcPGl1TBGRQqOiIlICtWkDK9b78uWXUK9qKscI5sms54gecxvvVxpFzjvvQ06O1TFFRC6biopICWWzwU03wYYdfnw01U5UhVQSqMQ9yROo98DVzI4ahn3ufJ0hJCIlmoqKSAnn6gq3D3Qhbp8fb0zMIcQvjW3E0CvhdZrfUplFDYZgVvxqdUwRkUuioiJSSnh6wsND3YhP8GHMUxn4eWSylqZ0+Ot12l2Vzm//exx+/FEjLCJSoqioiJQy/v4w8kUv/t7nyZC7U/FwyeZH2tLyl1e4uq0bX1Z5iNxJ70BqqtVRRUQuyGZMyf3nVUpKCoGBgSQnJxMQEGB1HBGntHs3jH3sOJ/M8yPb7gZANNsZ4jWFAXe44PvIXRATY3FKESlLCvL5raIiUkYkJMBbEzKYMgWOp3sBEMwR7mMKD7bZRPhjfaFz57xJLyIiRaggn9869CNSRkREwLhXvdib5MVbb9qpHp7GUcrzIs9Qddk07rjpMH9G3QgTJsDRo1bHFREBVFREyhw/P3jwIRe27fXhiy+gVZMMsvBkGncQu/9bOjwey/dhAzCD7oL1662OKyJlnIqKSBnl6grdu8OK371YuRJ6ds/BxWZnER3olP0VsR8+wtRGb5DZ6lr47DPIyrI6soiUQSoqIsKVV8KsL9zYEe/CIw8b/Lxz2UQD7mQqUStn8nyfTRyp0gjGjIHERKvjikgZoqIiIg7VqsHrb9jYm+DK+PFQKTyXg4QxgueJPLiG+0eHEhfZDnr0gEWLwG63OrKIlHI660dEzik7G2bNgokT7Kxb/++/a1ryK/35hN5Rqwi+vzfccQeEhlqYVERKkhJz1s/o0aOx2Wz5ltq1a1sZSURO4+4O/frB2j9c+Okn6NIFXFwMK2nFA7xD2O7f6D68JvMiBpPZo5+ufCsihc7yQz/16tUjMTHRsfzyyy9WRxKR/7DZ4JprYMEC2LfPxsSJ0LBBLtl4MI/udM+dTcQXb/JA262srNIb88oEOHzY6tgiUgpYXlTc3NwICwtzLBUqVLA6koicR3g4DB0K6ze6smEDDBsG4RWyOUp53uEBWu2bRa0nujI2bDJ/3/QoLFumURYRuWSWF5Xt27cTERFB9erV6devH3v27DnnupmZmaSkpORbRMQ6sbHwyiuw94A7338Pt92ajY9HNjuoyajcUdT46nX+d40L70eM4viLb+tCciJSYJZOpv32229JTU0lJiaGxMRExowZw/79+9m0aRP+/v5nrD969GjGjBlzxv2aTCviPFJTYe5c+GRyCktW+2H++feQJxl0cVnI7VfvptPoK3G/umXeMSURKXNK7Hf9HD9+nKioKF599VUGDRp0xuOZmZlkZmY6bqekpBAZGamiIuKk9u2DGR9m8PGUNP5KDHbcX4FDdPZeSkTACUICMgkNyiGkvJ3QijZCItwJqeyJZ8VyEBwMQUF5P4ODwcdH5UakFCixRQWgWbNmtGvXjnHjxl1wXZ2eLFIyGAPr1xk+eeUA0+f7kJQReMHnBJBMCIcIJenfny5HCfVJ/afcZBESbKdSFVdCmleDBg3yFs1zE3F6Bfn8diumTBclNTWV+Ph4+vfvb3UUESlENhs0amyj0cxwxufA4gUn+f37oxw6kMuhQ5B0xJVDye4knfDmcLovOcaNFAJJIZB4ov/dkB1I/WdJ+PfukOlJ1GcT9ZlB/cC9NKidQ73mvgQ0i8mbSFO7Nnh6FvNfLSKFwdIRlWHDhtGlSxeioqJISEhg1KhRrF+/ns2bNxMSEnLB52tERaT0MQaOH4ekJPJKTBIcSjIcSsgiaW8Whw7kcCjJkHQ4r9wcTPZyzIP5ryrsziswts3UjzhK/fpQu1Uw3k3q5o2+REbqUJKIBUrMiMq+ffvo06cPR44cISQkhKuuuorffvvtokqKiJRONlvetJSgIIiJcdwLeP6z5JeWBlu2wKZNsOmPLP5clcamODf2H/djD1HsIYpvzA2wH9gPLt/nEs0OGrCa+p4zqF/tJPUbuRPdJBC3IP+8r5f29c37ebbf3d2Lb2dIyZGdXTLfG8ZARgacOIFJTuFk0kmO7k/naGImR5NyOHYoh/A65Wg1pIVlEZ1ujkpBaERFRM7l2DH46y/Y9Kdh06rUvBKzw4ej6d7nfE4gxwni2BlLMEf/ve16giCfzLzFL5uggFwCA8HVzzuvzPj7/zv591yLt7dGckoiY/JmiG/ZAlu3On6mbd7F3iQPKoXZ8YutDvXqQf36eT/r1s17TxSHkychPh6zI55jmxM5ciCbo0cMR4/CsWQXjqa4cTTVg6NpXhzN8OZYli9HswM4ShBHCeYoweRwZtm6reovfLLzqkKNWqIn0xaEioqIFIQxcODAP6Mv63PY9GsKm/6089cef05mX/ocFht2AkhxlJlAkgkgJd/PfPe5pRMYCIHlbAQEuxEY4oF/iBeuFU47w6lcubx5Nf9dPDzOfr+nJ7i5qQAVhqws2LHjjEJyfEsiW9KqsIU6bKau4+duohyHH8NJoCbbqcl2arEt72d4KjUa+uEVW+vfAlOnTl5hLQhj8o6H/lNGDmw4SPymdHbE29iR6MOOk+HsIJodRJNMuUv+8z1sWQS7pRDskUqwVxodmh9nxDetLnl7Z6OiIiJSAHZ73v//Hzt2nuVILscO5XLsqD3v9nEXjqW4cDKj8I6g+3HCUWj8SMWdbNzJxo0cx89z/Z73Mxc3VzvurgY3N4ObG3h72AmpYAir5ErFqt5UjPYntG4F3KtVzpujExhYtsrNqUMdKSl5y+HDsG2bo4yYzVs4FJ/CZnvMGYUkkYhzbtbH205a+rmvoWrDTiR7HeWlpm0HtcJTqVnXnWrNKuAeWyevxNSoAQcPQnw89u3x7N9wmB1/ZbJjpys7kvzZkVWFHUQTTw1O4nfeP9XfPZ1g7wyCfTMJ8s8mOCCX4CBDcHkIruBKUKg7wWEeBFfyJjjCi+AKLgQFFc9VAFRURESKSVZW3uTf00tNSgokJ//789/fDSnHckk+mkvycUPKCReST7qSme1a7LnLc5iKHKSi62Eq+qQSFpRJxRA7FSu5UbGqN2E1/alYrwKhDcNxD/7PoQtj8g4znDiRf0lNPfO+/y4ZGf+OCnl55S2nfi/IfW5uea93qnBc5JKbnEpyri/HKcdxypFEKFupna+UHOHcp7hXqmSoU8dG3bp5gyKnfoaE5L0Ptm/P6z3bt//z++Yctu+A5NRzF1pXcqjGTmqynSrsIZFwRxnJxOucz3Ox2Ykql0x0ZCY1aroSfYUf0Q28iY6G6tULPmBTnFRURERKkMzMM8tNairk5OTN0czJyf97vvsyc8nJyCUnM5fsjFxysnLJzrCTk5VLTpadkyl2kg7kcvCwKweTvUhK9yfXFKwYBduOUsHtOC4mN2/4yW6/5L/VhsGHtDMWX06e9/Z/7/MgixQCHIXjbMsxgs647wQX/qyw2QzVqnFGIaldO28AqqBOHbFxlJc4w/ZNmWzfks32vV6kZZ17Eq6bSy7Vy6dQo0o20bXdiG7kT3Qdd6KjoWrVvM5XEqmoiIjIWdntcORI3tGFg7szOLj1GAd2nODg7kwOHrA7Cs2BtACScoLJda7LbRUaX19DuXI2goOhZk3yFZKYmOIbjTAGEhL+LTB7t6cTUc2L6FouREfnHZ1zK4X/CVRURETkstntcHRPKgc3HuTonlSMlzf4eIO3T95EBi+vAk9msNshPT3vyFFa2r9LQW6fPJl3yC0wMG/O8cUsQUH//h4YWDLPJC5NSsx1VERExHm5uECFqn5UqHr+SZsiRencU5RFRERELKaiIiIiIk5LRUVEREScloqKiIiIOC0VFREREXFaKioiIiLitFRURERExGmpqIiIiIjTUlERERERp6WiIiIiIk5LRUVEREScloqKiIiIOC0VFREREXFaKioiIiLitNysDnA5jDEApKSkWJxERERELtapz+1Tn+PnU6KLyokTJwCIjIy0OImIiIgU1IkTJwgMDDzvOjZzMXXGSdntdhISEvD398dmsxXqtlNSUoiMjGTv3r0EBAQU6rblX9rPxUP7uXhoPxcP7efiU1T72hjDiRMniIiIwMXl/LNQSvSIiouLC5UrVy7S1wgICND/EIqB9nPx0H4uHtrPxUP7ufgUxb6+0EjKKZpMKyIiIk5LRUVERESclorKOXh6ejJq1Cg8PT2tjlKqaT8XD+3n4qH9XDy0n4uPM+zrEj2ZVkREREo3jaiIiIiI01JREREREaeloiIiIiJOS0VFREREnJaKyllMnjyZqlWr4uXlRYsWLVi9erXVkUqd0aNHY7PZ8i21a9e2OlaJ9/PPP9OlSxciIiKw2WzMnz8/3+PGGEaOHEl4eDje3t60a9eO7du3WxO2BLvQfh44cOAZ7+9OnTpZE7YEGzduHM2aNcPf35/Q0FC6detGXFxcvnUyMjIYPHgw5cuXx8/Pj1tuuYWDBw9alLhkupj9fM0115zxnr7vvvuKJZ+Kyn98/vnnDB06lFGjRvHHH3/QsGFDOnbsSFJSktXRSp169eqRmJjoWH755RerI5V4J0+epGHDhkyePPmsj48fP54333yTKVOmsGrVKnx9fenYsSMZGRnFnLRku9B+BujUqVO+9/fMmTOLMWHpsGzZMgYPHsxvv/3GokWLyM7OpkOHDpw8edKxzpAhQ/jqq6+YPXs2y5YtIyEhge7du1uYuuS5mP0McPfdd+d7T48fP754AhrJp3nz5mbw4MGO27m5uSYiIsKMGzfOwlSlz6hRo0zDhg2tjlGqAWbevHmO23a73YSFhZlXXnnFcd/x48eNp6enmTlzpgUJS4f/7mdjjBkwYIDp2rWrJXlKs6SkJAOYZcuWGWPy3r/u7u5m9uzZjnW2bNliALNy5UqrYpZ4/93PxhjTpk0b88gjj1iSRyMqp8nKymLt2rW0a9fOcZ+Liwvt2rVj5cqVFiYrnbZv305ERATVq1enX79+7Nmzx+pIpdrOnTs5cOBAvvd3YGAgLVq00Pu7CCxdupTQ0FBiYmK4//77OXLkiNWRSrzk5GQAgoODAVi7di3Z2dn53tO1a9emSpUqek9fhv/u51OmT59OhQoVqF+/Pk899RRpaWnFkqdEfylhYTt8+DC5ublUrFgx3/0VK1Zk69atFqUqnVq0aMG0adOIiYkhMTGRMWPG8L///Y9Nmzbh7+9vdbxS6cCBAwBnfX+fekwKR6dOnejevTvVqlUjPj6ep59+muuvv56VK1fi6upqdbwSyW638+ijj9K6dWvq168P5L2nPTw8KFeuXL519Z6+dGfbzwB9+/YlKiqKiIgINm7cyJNPPklcXBxz584t8kwqKmKJ66+/3vF7bGwsLVq0ICoqilmzZjFo0CALk4lcvltvvdXxe4MGDYiNjaVGjRosXbqUtm3bWpis5Bo8eDCbNm3SXLYidq79fM899zh+b9CgAeHh4bRt25b4+Hhq1KhRpJl06Oc0FSpUwNXV9YwZ4wcPHiQsLMyiVGVDuXLlqFWrFjt27LA6Sql16j2s93fxq169OhUqVND7+xI9+OCDfP311/z0009UrlzZcX9YWBhZWVkcP3483/p6T1+ac+3ns2nRogVAsbynVVRO4+HhQZMmTViyZInjPrvdzpIlS2jZsqWFyUq/1NRU4uPjCQ8PtzpKqVWtWjXCwsLyvb9TUlJYtWqV3t9FbN++fRw5ckTv7wIyxvDggw8yb948fvzxR6pVq5bv8SZNmuDu7p7vPR0XF8eePXv0ni6AC+3ns1m/fj1AsbyndejnP4YOHcqAAQNo2rQpzZs35/XXX+fkyZPccccdVkcrVYYNG0aXLl2IiooiISGBUaNG4erqSp8+fayOVqKlpqbm+xfOzp07Wb9+PcHBwVSpUoVHH32U559/npo1a1KtWjVGjBhBREQE3bp1sy50CXS+/RwcHMyYMWO45ZZbCAsLIz4+nieeeILo6Gg6duxoYeqSZ/DgwcyYMYMvv/wSf39/x7yTwMBAvL29CQwMZNCgQQwdOpTg4GACAgJ46KGHaNmyJVdeeaXF6UuOC+3n+Ph4ZsyYQefOnSlfvjwbN25kyJAhXH311cTGxhZ9QEvONXJyb731lqlSpYrx8PAwzZs3N7/99pvVkUqd3r17m/DwcOPh4WEqVapkevfubXbs2GF1rBLvp59+MsAZy4ABA4wxeacojxgxwlSsWNF4enqatm3bmri4OGtDl0Dn289paWmmQ4cOJiQkxLi7u5uoqChz9913mwMHDlgdu8Q52z4GzNSpUx3rpKenmwceeMAEBQUZHx8fc/PNN5vExETrQpdAF9rPe/bsMVdffbUJDg42np6eJjo62jz++OMmOTm5WPLZ/gkpIiIi4nQ0R0VEREScloqKiIiIOC0VFREREXFaKioiIiLitFRURERExGmpqIiIiIjTUlERERERp6WiIiIiIk5LRUVEpARbunQpNpvtjC/mEyktVFRELtOhQ4e4//77qVKlCp6enoSFhdGxY0dWrFjhWMdmszF//nzrQhbAqQ++sy2nvgPEmSQmJtK3b19q1aqFi4sLjz766FnXmz17NrVr18bLy4sGDRrwzTff5HvcGMPIkSMJDw/H29ubdu3asX379mL4C0TkfFRURC7TLbfcwrp16/joo4/Ytm0bCxYs4JprruHIkSNWR7sscXFxJCYm5ltCQ0OL7PWysrIu6XmZmZmEhITw7LPP0rBhw7Ou8+uvv9KnTx8GDRrEunXr6NatG926dWPTpk2OdcaPH8+bb77JlClTWLVqFb6+vnTs2JGMjIxLyiUihaRYvlFIpJQ6duyYAczSpUvPuU5UVFS+L/qKiopyPDZ//nzTqFEj4+npaapVq2ZGjx5tsrOzHY8D5u233zadOnUyXl5eplq1amb27NmOxzMzM83gwYNNWFiY8fT0NFWqVDEvvvjiZf1Np75w79ixY2d9/Pvvvzeenp5nPP7www+ba6+91nF7+fLl5qqrrjJeXl6mcuXK5qGHHjKpqan59svYsWNN//79jb+/vxkwYIC59tprzeDBg/NtNykpybi7u5vFixdfMHubNm3MI488csb9vXr1MjfccEO++1q0aGHuvfdeY0zelzWGhYWZV155xfH48ePHjaenp5k5c+Y5Xy83N9e8+OKLpmrVqsbLy8vExsbm++9zal9+/fXXpkGDBsbT09O0aNHC/Pnnn/m2M2fOHFO3bl3j4eFhoqKizIQJE/I9npGRYZ544glTuXJl4+HhYWrUqGH+7//+L99rLF682DRp0sR4e3ubli1bmq1btzqev379enPNNdcYPz8/4+/vbxo3bmzWrFlzgb0p4hxUVEQuQ3Z2tvHz8zOPPvqoycjIOOs6SUlJjm8iTUxMNElJScYYY37++WcTEBBgpk2bZuLj480PP/xgqlatakaPHu14LmDKly9v3n//fRMXF2eeffZZ4+rqajZv3myMMeaVV14xkZGR5ueffza7du0yy5cvNzNmzLisv+lCRSUnJ8dUrFjR8UF5tvt27NhhfH19zWuvvWa2bdtmVqxYYRo1amQGDhzoeE5UVJQJCAgwEyZMMDt27DA7duww06dPN0FBQfn25auvvmqqVq1q7Hb7BbOfq6hERkaa1157Ld99I0eONLGxscYYY+Lj4w1g1q1bl2+dq6++2jz88MPnfL3nn3/e1K5d23z33XcmPj7eTJ061Xh6ejqK66l9WadOHfPDDz+YjRs3mhtvvNFUrVrVZGVlGWOM+f33342Li4sZO3asiYuLM1OnTjXe3t75viG4V69eJjIy0sydO9fEx8ebxYsXm88++yzfa7Ro0cIsXbrU/PXXX+Z///ufadWqleP59erVM7fddpvZsmWL2bZtm5k1a5ZZv379BfeniDNQURG5THPmzDFBQUHGy8vLtGrVyjz11FNmw4YN+dYBzLx58/Ld17Zt2zNGPz755BMTHh6e73n33XdfvnVatGhh7r//fmOMMQ899JC57rrrLupD/GKd+uDz9fXNt9StW9exziOPPGKuu+46x+3/jrIMGjTI3HPPPfm2u3z5cuPi4mLS09ONMXlFpVu3bvnWSU9PN0FBQebzzz933BcbG5uvvJ3PuYqKu7v7GQVu8uTJJjQ01BhjzIoVKwxgEhIS8q3Ts2dP06tXr7O+VkZGhvHx8TG//vprvvsHDRpk+vTpY4z5d1+eKhXGGHPkyBHj7e3t+Bv79u1r2rdvn28bjz/+uGN/x8XFGcAsWrTorDlOH1E5ZeHChQZw7Gt/f38zbdq0sz5fxNlpjorIZbrllltISEhgwYIFdOrUiaVLl9K4cWOmTZt23udt2LCBsWPH4ufn51juvvtuEhMTSUtLc6zXsmXLfM9r2bIlW7ZsAWDgwIGsX7+emJgYHn74YX744Ydzvt7y5cvzvdb06dPPm2/58uWsX7/esZw++bRfv34sXbqUhIQEAKZPn84NN9xAuXLlHH/btGnT8r1ex44dsdvt7Ny507Gdpk2b5ntNLy8v+vfvz4cffgjAH3/8waZNmxg4cOB5s1phx44dpKWl0b59+3x/58cff0x8fHy+dU//bxgcHExMTIzjv+GWLVto3bp1vvVbt27N9u3byc3NZf369bi6utKmTZvz5omNjXX8Hh4eDkBSUhIAQ4cO5a677qJdu3a89NJLZ+QTcWZuVgcQKQ28vLxo37497du3Z8SIEdx1112MGjXqvB+wqampjBkzhu7du591exejcePG7Ny5k2+//ZbFixfTq1cv2rVrx5w5c85Yt2nTpqxfv95xu2LFiufddrVq1RzF47+aNWtGjRo1+Oyzz7j//vuZN29evmKWmprKvffey8MPP3zGc6tUqeL43dfX94zH77rrLq644gr27dvH1KlTue6664iKijpv1gsJCwvj4MGD+e47ePAgYWFhjsdP3XfqQ/7U7SuuuOKs20xNTQVg4cKFVKpUKd9jnp6el5X3dN7e3he1nru7u+N3m80GgN1uB2D06NH07duXhQsX8u233zJq1Cg+++wzbr755kLLKVJUVFREikDdunXznY7s7u5Obm5uvnUaN25MXFwc0dHR593Wb7/9xu23357vdqNGjRy3AwIC6N27N71796ZHjx506tSJo0ePEhwcnG873t7eF3ytgujXrx/Tp0+ncuXKuLi4cMMNNzgea9y4MZs3b76k12vQoAFNmzbl/fffZ8aMGUyaNOmys7Zs2ZIlS5bkO3V50aJFjpGOatWqERYWxpIlSxzFJCUlhVWrVnH//fefdZt169bF09OTPXv2XHC047fffnMUtGPHjrFt2zbq1KkDQJ06dfKdyg6wYsUKatWqhaurKw0aNMBut7Ns2TLatWt3KX8+ALVq1aJWrVoMGTKEPn36MHXqVBUVKRmsPvYkUpIdPnzYXHvtteaTTz4xGzZsMH///beZNWuWqVixornzzjsd69WsWdPcf//9JjEx0Rw9etQYY8x3331n3NzczOjRo82mTZvM5s2bzcyZM80zzzzjeB5gKlSoYD744AMTFxdnRo4caVxcXMxff/1ljDFm4sSJZsaMGWbLli0mLi7ODBo0yISFhZnc3NxL/ptOzXmIi4sziYmJ+ZZTE0CNMWb79u0GMLGxsWbQoEH5trFhwwbj7e1tBg8ebNatW2e2bdtm5s+fn++MnqioqDMmuJ7y3nvvGQ8PDxMUFOSYZ3E+69atM+vWrTNNmjQxffv2NevWrXPsI2Py5qC4ubmZCRMmmC1btphRo0YZd3f3fGffvPTSS6ZcuXLmyy+/NBs3bjRdu3Y11apVO+/rP/PMM6Z8+fJm2rRpZseOHWbt2rXmzTffdMwHObUv69WrZxYvXmz+/PNPc9NNN5kqVaqYzMxMY4wxa9euzTeZdtq0aWdMph04cKCJjIw08+bNM3///bf56aefHHNczjb5ed26dQYwO3fuNGlpaWbw4MHmp59+Mrt27TK//PKLqVGjhnniiScuuF9FnIGKishlyMjIMMOHDzeNGzc2gYGBxsfHx8TExJhnn33WpKWlOdZbsGCBiY6ONm5ubvlOT/7uu+9Mq1atjLe3twkICDDNmzc37733nuNxwEyePNm0b9/eeHp6mqpVq+abaPree++ZK664wvj6+pqAgADTtm1b88cff1zW33Tqg+9sy8qVK/Ot27x5cwOYH3/88YztrF692rRv3974+fkZX19fExsba1544QXH4+crKidOnDA+Pj7mgQceuKjMZ8t6+n42xphZs2aZWrVqGQ8PD1OvXj2zcOHCfI/b7XYzYsQIU7FiRePp6Wnatm1r4uLizvu6drvdvP766yYmJsa4u7ubkJAQ07FjR7Ns2TJjzL/78quvvjL16tUzHh4epnnz5mdMtj51erK7u7upUqVKvtOkjcmbZDxkyBATHh5uPDw8THR0tPnwww/zvca5ikpmZqa59dZbTWRkpPHw8DARERHmwQcfvKgCKOIMbMYYU5wjOCJy8Ww2G/PmzaNbt25WRylWu3btokaNGqxZs4bGjRtbHeeSLV26lGuvvZZjx46dc76PiJyf5qiIiNPIzs7myJEjPPvss1x55ZUluqSISOHQ6cki4jRWrFhBeHg4a9asYcqUKVbHEREnoEM/IiIi4rQ0oiIiIiJOS0VFREREnJaKioiIiDgtFRURERFxWioqIiIi4rRUVERERMRpqaiIiIiI01JREREREaf1/0o5Bop5zRuYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\n",
    "validation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n",
    "\n",
    "plt.plot(train_loss_list_converted, 'r', label='train_loss')\n",
    "plt.plot(validation_loss_list_converted, 'b', label='validation_loss')\n",
    "plt.xlabel(\"Steps - Every 100 epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:52:47.803588Z",
     "iopub.status.busy": "2025-11-09T09:52:47.803314Z",
     "iopub.status.idle": "2025-11-09T09:52:48.038187Z",
     "shell.execute_reply": "2025-11-09T09:52:48.037403Z",
     "shell.execute_reply.started": "2025-11-09T09:52:47.803568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and config saved in: /kaggle/working/small_gpt_model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "save_dir = \"/kaggle/working/small_gpt_model\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(save_dir, \"small_gpt_weights.pt\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "import json\n",
    "config_dict = {\n",
    "    \"block_size\": config.block_size,\n",
    "    \"vocab_size\": config.vocab_size,\n",
    "    \"n_layer\": config.n_layer,\n",
    "    \"n_head\": config.n_head,\n",
    "    \"n_embd\": config.n_embd,\n",
    "    \"dropout\": config.dropout,\n",
    "    \"bias\": config.bias\n",
    "}\n",
    "with open(os.path.join(save_dir, \"config.json\"), \"w\") as f:\n",
    "    json.dump(config_dict, f, indent=2)\n",
    "\n",
    "print(f\"✅ Model and config saved in: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:53:19.303983Z",
     "iopub.status.busy": "2025-11-09T09:53:19.303680Z",
     "iopub.status.idle": "2025-11-09T09:53:19.308309Z",
     "shell.execute_reply": "2025-11-09T09:53:19.307471Z",
     "shell.execute_reply.started": "2025-11-09T09:53:19.303961Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(save_dir, \"tokenizer.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(enc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8687346,
     "sourceId": 13663813,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
